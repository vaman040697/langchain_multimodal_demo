{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812a4dbc-fe04-4b84-bdf9-390045e30806",
   "metadata": {
    "id": "812a4dbc-fe04-4b84-bdf9-390045e30806"
   },
   "source": [
    "# Multi-modal RAG with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecXPgawqG7XH",
   "metadata": {
    "id": "ecXPgawqG7XH"
   },
   "source": [
    "## SetUp\n",
    "\n",
    "Install the dependencies you need to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "29623366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T08:29:33.887638Z",
     "start_time": "2025-03-09T08:29:33.548877Z"
    }
   },
   "source": [
    "pip install ipykernel -U --user --force-reinstall"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "133b74f6",
   "metadata": {
    "id": "133b74f6",
    "ExecuteTime": {
     "end_time": "2025-03-09T08:46:13.151631Z",
     "start_time": "2025-03-09T08:46:13.149232Z"
    }
   },
   "source": [
    "# for linux\n",
    "# %sudo apt-get install poppler-utils tesseract-ocr libmagic-dev\n",
    "\n",
    "# for mac\n",
    "#%brew install poppler tesseract libmagic"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%brew` not found.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T08:48:43.557990Z",
     "start_time": "2025-03-09T08:46:48.676027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(\"/opt/homebrew/bin/brew install poppler tesseract libmagic\", shell=True, check=True)"
   ],
   "id": "eea7ecdd51aa383c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Downloading https://ghcr.io/v2/homebrew/core/poppler/manifests/25.03.0\n",
      "==> Fetching dependencies for poppler: libpng, freetype, fontconfig, pcre2, libunistring, gettext, glib, xorgproto, libxau, libxdmcp, libxcb, libx11, libxext, libxrender, lzo, pixman, cairo, ca-certificates, gmp, libidn2, libtasn1, nettle, p11-kit, openssl@3, libevent, libnghttp2, unbound, gnutls, libgpg-error, libassuan, libgcrypt, libksba, libusb, npth, pinentry, readline, gnupg, gpgme, jpeg-turbo, xz, lz4, zstd, libtiff, little-cms2, nspr, nss and openjpeg\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libpng/manifests/1.6.47\n",
      "==> Fetching libpng\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libpng/blobs/sha256:b4a7f252793b6a2d9d111cecaf5f0c91fd91d9c1c174a8796a487621a05f6f24\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/freetype/manifests/2.13.3\n",
      "==> Fetching freetype\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/freetype/blobs/sha256:bcd39d3a523690cb0673df46122ff62763c5cd93bfff21bdcab856501d2dfb49\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fontconfig/manifests/2.16.0\n",
      "==> Fetching fontconfig\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fontconfig/blobs/sha256:c3a7405dd151a87f72e7f99c95150da1fc8320ee817c3a17f15a493e1e01057c\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/manifests/10.44\n",
      "==> Fetching pcre2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/blobs/sha256:c3f9e7a70ebc0986af6f0b7c69ac1495fdf4c7420ad831d3daa9c86c448b79c2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.3\n",
      "==> Fetching libunistring\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:3cd26bae2d5fcf61294f14c18e5e7ec773a59ed1bf710fb92055e0db0244e909\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gettext/manifests/0.24\n",
      "==> Fetching gettext\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gettext/blobs/sha256:be3555b4d0ed00fd50720e3f467cf9ca91fe0645ba29ba206f6bff2763b97e79\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/glib/manifests/2.82.5\n",
      "==> Fetching glib\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/glib/blobs/sha256:1cb81bf4e51c9d5f2076bd25f048d54e3dfef275a56181ae556d0f00202134f9\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xorgproto/manifests/2024.1\n",
      "==> Fetching xorgproto\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xorgproto/blobs/sha256:91066363512e4a3b01644398886815eb370bc8f62611f7ee20c23c7350b4422e\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxau/manifests/1.0.12\n",
      "==> Fetching libxau\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxau/blobs/sha256:e8a5fedbd9e5c49f10006171decc5b1e56c48fbd4267e7668f813e47c0da984f\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxdmcp/manifests/1.1.5\n",
      "==> Fetching libxdmcp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxdmcp/blobs/sha256:b09a915dae5b45371a86f20a4ccce13c16c7a8eadc843b665e91bc5b2d2143ce\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxcb/manifests/1.17.0-1\n",
      "==> Fetching libxcb\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxcb/blobs/sha256:cce8d9e12c3f0b2fdbffbb3f7ba02f7e25cf3fa495b3e759d34a6264599543b3\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libx11/manifests/1.8.11\n",
      "==> Fetching libx11\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libx11/blobs/sha256:defefa00e824a71099e3dae6bbf18ae7bd728f7adacba32be6b0ef9d6fd12cf2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxext/manifests/1.3.6\n",
      "==> Fetching libxext\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxext/blobs/sha256:a0434e871b6dfa64f18757e5d6df179308bcf1b53e5fa233c7d54222be8d513b\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxrender/manifests/0.9.12\n",
      "==> Fetching libxrender\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxrender/blobs/sha256:edcb8884f9d33219d276051be3b5ad64f390cdf3abe9794d9a0050c02895c3a7\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lzo/manifests/2.10\n",
      "==> Fetching lzo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lzo/blobs/sha256:6bb0401c41a18fd37071ec9591fe053a808f07552ff7ea22542faa470eb8e589\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pixman/manifests/0.44.2\n",
      "==> Fetching pixman\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pixman/blobs/sha256:8ec43a3f69d7c97d8ce1d07611638040c8ebec305e7dd76cb02dc3609982fa9f\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/cairo/manifests/1.18.4\n",
      "==> Fetching cairo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/cairo/blobs/sha256:6b2d148a34a670430a459c374376ebed890b61eb7573e8aa952a4b909f443cee\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/manifests/2025-02-25\n",
      "==> Fetching ca-certificates\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/blobs/sha256:8f46fb05f753f80f2bc398c0a24b10d680bd77d496e2b931de0b61998e37aebc\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/manifests/6.3.0\n",
      "==> Fetching gmp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/blobs/sha256:6683d73d6677d28e1e8d1b92d6ebfbc068c1d33e19b79114a22a648a99ba5991\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.7\n",
      "==> Fetching libidn2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:1da206a51b4e3550f75e2c980f7f32ad7c75a3824711c534e4b3a9a21fcbaa1a\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtasn1/manifests/4.20.0\n",
      "==> Fetching libtasn1\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtasn1/blobs/sha256:e847b97b86b1caab2eff1498c82c411459e1e7c176de72e6c53aed4528ab80ce\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nettle/manifests/3.10.1\n",
      "==> Fetching nettle\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nettle/blobs/sha256:df8b22b1a4deeafeae7f4afe13cd7403a3700c7779715916c43a45fad7ca5aaa\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/p11-kit/manifests/0.25.5-1\n",
      "==> Fetching p11-kit\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/p11-kit/blobs/sha256:a411c523067edccdf5288ff53f725d590c60d0a182f1e69238fcfc86018f3395\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/manifests/3.4.1\n",
      "==> Fetching openssl@3\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/blobs/sha256:b20c7d9b63e7b320cba173c11710dee9888c77175a841031d7a245bb37355b98\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libevent/manifests/2.1.12_1\n",
      "==> Fetching libevent\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libevent/blobs/sha256:65fc7c61fec0f5ae0c5dfc8fc7e3b6b0507d3f1c7c308a332802541f00334963\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/manifests/1.65.0\n",
      "==> Fetching libnghttp2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/blobs/sha256:492e4dadaeb76e53e56b15180eb4ab33d8e726d5766f258f94d3628382e7a8e2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/unbound/manifests/1.22.0\n",
      "==> Fetching unbound\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/unbound/blobs/sha256:b1b2f3ec332c26033f00996f6caa847652848647e1a29d68fb9059547ace2373\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnutls/manifests/3.8.4\n",
      "==> Fetching gnutls\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnutls/blobs/sha256:e927eab61e775a8b65079c2163fb29b9f03c90caf68cc13788dfea249ed6201e\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgpg-error/manifests/1.51\n",
      "==> Fetching libgpg-error\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgpg-error/blobs/sha256:7db996510272893e4db9cd536e65e7fa6d0f20c4dbef13c55e95a3ebab67d103\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libassuan/manifests/3.0.2\n",
      "==> Fetching libassuan\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libassuan/blobs/sha256:1430611fe9f337d6a7568a12321f125c567ca8d4d2bdcd7ff0717bdcd82a32dc\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgcrypt/manifests/1.11.0\n",
      "==> Fetching libgcrypt\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgcrypt/blobs/sha256:d6010619edaf0b17877797dc4beb14c1ccb423833e864bf9e2990cf4c21373ce\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libksba/manifests/1.6.7\n",
      "==> Fetching libksba\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libksba/blobs/sha256:4446cbe4b0a27393b01c2627edfad9cfebb8a55fae70750977ec786d4598e64a\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libusb/manifests/1.0.27\n",
      "==> Fetching libusb\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libusb/blobs/sha256:872182eebb566f32d577fa82b126260c383c6a8f8d02e9fc232eadda9184060b\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/npth/manifests/1.8\n",
      "==> Fetching npth\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/npth/blobs/sha256:7836af0109be87ab2b8155b533cd33508eb3b738190031c8ca2e2b94df6f5c2b\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pinentry/manifests/1.3.1_1\n",
      "==> Fetching pinentry\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pinentry/blobs/sha256:1d5fc3eb19d7e41caa4a8b61530e7040d0f3fbffb812ca24e116d6b247a0dadc\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/readline/manifests/8.2.13\n",
      "==> Fetching readline\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/readline/blobs/sha256:738c27ceee9a8b198f98438477ef7a513a96a965e3a434ac3aa8fb4ed76494b1\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnupg/manifests/2.4.7\n",
      "==> Fetching gnupg\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnupg/blobs/sha256:47b40c87309680baa445bb8b9bb71c94f7c9020789a6ae5f45980febeb6d1e42\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gpgme/manifests/1.24.2\n",
      "==> Fetching gpgme\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gpgme/blobs/sha256:f050cd4be93a9a506d374f44be63b13f0063bea568c7508c947be36cd4fcf510\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/jpeg-turbo/manifests/3.1.0\n",
      "==> Fetching jpeg-turbo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/jpeg-turbo/blobs/sha256:c43b108ab9895d7aa1f649d9d3b10da482657eb1216d060577142b805cfe490c\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xz/manifests/5.6.4\n",
      "==> Fetching xz\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xz/blobs/sha256:b49f3559f9425b0a8c8de8806b2162d757196c06d4043e65c6654e88cdac15e0\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/manifests/1.10.0-1\n",
      "==> Fetching lz4\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/blobs/sha256:5bd143b7b784989e549637ea4e484af85ba481e640dde69bc35f3843ae25abc6\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/manifests/1.5.7\n",
      "==> Fetching zstd\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/blobs/sha256:b039c851ef22617804576274872c33727ebb3a0b5e0db2ab62e0d8a97ec9605a\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtiff/manifests/4.7.0-1\n",
      "==> Fetching libtiff\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtiff/blobs/sha256:5f771cedcb37119c3927c32d72589a66701db16fe3ef86b2daf9b87c3142b309\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/little-cms2/manifests/2.17\n",
      "==> Fetching little-cms2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/little-cms2/blobs/sha256:3827b5a8583f0e92987bd0e7c721bda834157ad366d2cb66596559dd8654c9ac\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nspr/manifests/4.36\n",
      "==> Fetching nspr\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nspr/blobs/sha256:74fa5a145de56d105daeb2686e5e998a926602260b87d8bcd3d8331ae89fc313\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nss/manifests/3.109\n",
      "==> Fetching nss\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nss/blobs/sha256:b478d21a9015b22d000c2b1c63a9ea73fcba94cc23845743ec0b68681ad00118\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openjpeg/manifests/2.5.3\n",
      "==> Fetching openjpeg\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openjpeg/blobs/sha256:a8091181f4cdd66cc41e7c4bebdfb205c70fc52c069f8ddfdc26bc91e3fa417a\n",
      "==> Fetching poppler\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/poppler/blobs/sha256:b01bb7c9e277a3e201791fe79db584c2935eb484d195ddafd5657d9da8540834\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/tesseract/manifests/5.5.0\n",
      "==> Fetching dependencies for tesseract: graphite2, icu4c@76, harfbuzz, giflib, webp, leptonica, libb2, libarchive, fribidi and pango\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/graphite2/manifests/1.3.14\n",
      "==> Fetching graphite2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/graphite2/blobs/sha256:150b286ab4cfc8696fcd3fa4e7fa24c9825f024ef991899850b850e6f334100f\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/icu4c/76/manifests/76.1_1\n",
      "==> Fetching icu4c@76\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/icu4c/76/blobs/sha256:66a2995c046a7d78b727cac1b90f52a2fd3bcf07488ae41c711109bbd1fca8e1\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/harfbuzz/manifests/10.4.0\n",
      "==> Fetching harfbuzz\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/harfbuzz/blobs/sha256:3f8f12c182943f1c4215b3bae44d0d729fd478620a89b9f4e04ad79b8eb740a0\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/giflib/manifests/5.2.2\n",
      "==> Fetching giflib\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/giflib/blobs/sha256:bf188a3d3e386e0b100831ca92173118c74645b033b56b4a7c148a91c2cfecb5\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/webp/manifests/1.5.0\n",
      "==> Fetching webp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/webp/blobs/sha256:700e1f0c8a32f99de402e714237c786191c5ef782b8639b2f2b1c5794b025825\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/leptonica/manifests/1.85.0\n",
      "==> Fetching leptonica\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/leptonica/blobs/sha256:d2d966918337ee5feda18544d4546734f77aeaf4dde87ae8979589bd97c799c1\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libb2/manifests/0.98.1\n",
      "==> Fetching libb2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libb2/blobs/sha256:cc4304b760722128b914944f85788795f1f02de3072d1fd8e921b836b508776f\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libarchive/manifests/3.7.7\n",
      "==> Fetching libarchive\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libarchive/blobs/sha256:faa2ce394a18275219d6962a94b179069c03e4984def0e50c1b24299faf6c241\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fribidi/manifests/1.0.16\n",
      "==> Fetching fribidi\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fribidi/blobs/sha256:4904bb3375c1b1f2539cb657fbf17b0d93c050904febbba51e9dd690f3540e3b\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pango/manifests/1.56.1\n",
      "==> Fetching pango\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pango/blobs/sha256:48507210c600d918ab097c8be972714d2d221ec7d57590aa01a7543dd73ff96d\n",
      "==> Fetching tesseract\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/tesseract/blobs/sha256:5caba25c2552970a19808a6b2e1e937d58f1eda75f81236da444f79d099f3bcd\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libmagic/manifests/5.46\n",
      "==> Fetching libmagic\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libmagic/blobs/sha256:72bb18819cf63d14cdc3c830d586bd93e542f5cf2cdbbc579bfcd5170017fff1\n",
      "==> Installing dependencies for poppler: libpng, freetype, fontconfig, pcre2, libunistring, gettext, glib, xorgproto, libxau, libxdmcp, libxcb, libx11, libxext, libxrender, lzo, pixman, cairo, ca-certificates, gmp, libidn2, libtasn1, nettle, p11-kit, openssl@3, libevent, libnghttp2, unbound, gnutls, libgpg-error, libassuan, libgcrypt, libksba, libusb, npth, pinentry, readline, gnupg, gpgme, jpeg-turbo, xz, lz4, zstd, libtiff, little-cms2, nspr, nss and openjpeg\n",
      "==> Installing poppler dependency: libpng\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libpng/manifests/1.6.47\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/072d8f136f69cf75140ffb8a832f60b362a14dba897d78ed7fc83e3ca30b2ede--libpng-1.6.47.bottle_manifest.json\n",
      "==> Pouring libpng--1.6.47.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libpng/1.6.47: 28 files, 1.3MB\n",
      "==> Installing poppler dependency: freetype\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/freetype/manifests/2.13.3\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/4c4d14d574a7af9a5a0220cd5012c698bd87b75a3d5e39a6a6c34b4c411aab52--freetype-2.13.3.bottle_manifest.json\n",
      "==> Pouring freetype--2.13.3.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/freetype/2.13.3: 68 files, 2.5MB\n",
      "==> Installing poppler dependency: fontconfig\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fontconfig/manifests/2.16.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/6897fed6b85e0f537cb8774ec21346308111caaf26c136f33fdc95302d361fe7--fontconfig-2.16.0.bottle_manifest.json\n",
      "==> Pouring fontconfig--2.16.0.arm64_sequoia.bottle.tar.gz\n",
      "\u001B[34m==>\u001B[0m \u001B[1mRegenerating font cache, this may take a while\u001B[0m\r\n",
      "\u001B[34m==>\u001B[0m \u001B[1m/opt/homebrew/Cellar/fontconfig/2.16.0/bin/fc-cache -frv\u001B[0m\r\n",
      "🍺  /opt/homebrew/Cellar/fontconfig/2.16.0: 92 files, 1.5MB\n",
      "==> Installing poppler dependency: pcre2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/manifests/10.44\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/22ed791461c5bf400adde8c3b432c1230866aa1db3c5cb81e06a6ff21cac96ee--pcre2-10.44.bottle_manifest.json\n",
      "==> Pouring pcre2--10.44.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/pcre2/10.44: 237 files, 6.3MB\n",
      "==> Installing poppler dependency: libunistring\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.3\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/a570da63bc1839c7e217f203abd54d4d873ebd6b99f6e88994d0e79e2ebe987c--libunistring-1.3.bottle_manifest.json\n",
      "==> Pouring libunistring--1.3.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libunistring/1.3: 59 files, 5.4MB\n",
      "==> Installing poppler dependency: gettext\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gettext/manifests/0.24\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/8abb4a73a097ce307663b52d2da2d1d9b10df035244eb566425042eee157d0b3--gettext-0.24.bottle_manifest.json\n",
      "==> Pouring gettext--0.24.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/gettext/0.24: 2,189 files, 19.9MB\n",
      "==> Installing poppler dependency: glib\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/glib/manifests/2.82.5\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/13279fde2e70b004c1e3429f26949a17f260ab4261ac6c9910d83d781d40aeee--glib-2.82.5.bottle_manifest.json\n",
      "==> Pouring glib--2.82.5.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/glib/2.82.5: 504 files, 36.3MB\n",
      "==> Installing poppler dependency: xorgproto\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xorgproto/manifests/2024.1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/d89d69340366d1d015e7214520f64081e2d82d7955fb28c6ea5f6539dcb610b2--xorgproto-2024.1.bottle_manifest.json\n",
      "==> Pouring xorgproto--2024.1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/xorgproto/2024.1: 268 files, 3.9MB\n",
      "==> Installing poppler dependency: libxau\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxau/manifests/1.0.12\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/6335be202d59f96fdee2e4a02f93d8ee87dfcfdbaa4ed132b8fe8c3e3651e27c--libxau-1.0.12.bottle_manifest.json\n",
      "==> Pouring libxau--1.0.12.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libxau/1.0.12: 21 files, 134.3KB\n",
      "==> Installing poppler dependency: libxdmcp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxdmcp/manifests/1.1.5\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/8713e53f73d0be64780dbea522b0ee07027e6cc7828ff1a4fa0a6596f14cfe25--libxdmcp-1.1.5.bottle_manifest.json\n",
      "==> Pouring libxdmcp--1.1.5.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libxdmcp/1.1.5: 12 files, 140.0KB\n",
      "==> Installing poppler dependency: libxcb\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxcb/manifests/1.17.0-1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/a17e9d0e04a0013a5be592875b012c409023664b3df084b8051766331d213ff5--libxcb-1.17.0-1.bottle_manifest.json\n",
      "==> Pouring libxcb--1.17.0.arm64_sequoia.bottle.1.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libxcb/1.17.0: 2,498 files, 7.5MB\n",
      "==> Installing poppler dependency: libx11\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libx11/manifests/1.8.11\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/892d2a9a8a3fc139f37fcd1a9a1cc6e112a48ed4a33da24e4ea5d3b0046436d3--libx11-1.8.11.bottle_manifest.json\n",
      "==> Pouring libx11--1.8.11.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libx11/1.8.11: 1,043 files, 7MB\n",
      "==> Installing poppler dependency: libxext\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxext/manifests/1.3.6\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/fedb843acbfcf682fb451396914bfc096f9ea2748376d4c43ce2af7ce1b766b7--libxext-1.3.6.bottle_manifest.json\n",
      "==> Pouring libxext--1.3.6.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libxext/1.3.6: 88 files, 458.5KB\n",
      "==> Installing poppler dependency: libxrender\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libxrender/manifests/0.9.12\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/152fb22ff88a23b62841dcfa14aac21018e1d736c072d732185f6139ef922e1c--libxrender-0.9.12.bottle_manifest.json\n",
      "==> Pouring libxrender--0.9.12.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libxrender/0.9.12: 13 files, 225.3KB\n",
      "==> Installing poppler dependency: lzo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lzo/manifests/2.10\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/d4aa5b0c239912c53bc857d1012c6b7feb4acb509618f5e100f95bf8521f08e7--lzo-2.10.bottle_manifest.json\n",
      "==> Pouring lzo--2.10.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/lzo/2.10: 32 files, 567.9KB\n",
      "==> Installing poppler dependency: pixman\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pixman/manifests/0.44.2\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/710d020ae0348db5aff5d6dbdfd222dca000e630d64e8dcd5f8a8499e8131681--pixman-0.44.2.bottle_manifest.json\n",
      "==> Pouring pixman--0.44.2.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/pixman/0.44.2: 10 files, 655.6KB\n",
      "==> Installing poppler dependency: cairo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/cairo/manifests/1.18.4\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/795ef2e2e2a57e6baba0fc9ceedb58980e8ec718aba0170b9441a0b25442cfbf--cairo-1.18.4.bottle_manifest.json\n",
      "==> Pouring cairo--1.18.4.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/cairo/1.18.4: 53 files, 2.2MB\n",
      "==> Installing poppler dependency: ca-certificates\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/manifests/2025-02-25\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/6c1debb525d4dc6007afae4cd2b772105111632b22fc28506550f6dfe27c6d52--ca-certificates-2025-02-25.bottle_manifest.json\n",
      "==> Pouring ca-certificates--2025-02-25.all.bottle.tar.gz\n",
      "\u001B[34m==>\u001B[0m \u001B[1mRegenerating CA certificate bundle from keychain, this may take a while...\u001B[0m\r\n",
      "🍺  /opt/homebrew/Cellar/ca-certificates/2025-02-25: 4 files, 235.9KB\n",
      "==> Installing poppler dependency: gmp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/manifests/6.3.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/70a72a71216843d66a953c06ff6337445ce9bc94fae9f0e301e2f59005274a8e--gmp-6.3.0.bottle_manifest.json\n",
      "==> Pouring gmp--6.3.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/gmp/6.3.0: 22 files, 3.3MB\n",
      "==> Installing poppler dependency: libidn2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.7\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/45d1d4d2930c4782bf53e761a1c0166cd8a40f4193ac8c44e86f0b6708e80354--libidn2-2.3.7.bottle_manifest.json\n",
      "==> Pouring libidn2--2.3.7.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libidn2/2.3.7: 81 files, 1MB\n",
      "==> Installing poppler dependency: libtasn1\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtasn1/manifests/4.20.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/0d8e273dbfaade0247db22d4d5abf7e8d4d6c379f7912adc81c60e5d4418e8ca--libtasn1-4.20.0.bottle_manifest.json\n",
      "==> Pouring libtasn1--4.20.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libtasn1/4.20.0: 63 files, 689.8KB\n",
      "==> Installing poppler dependency: nettle\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nettle/manifests/3.10.1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/3a897a4b5866bef2225eb637641c992e5903a0748ec913a0747a253dcee0c4d8--nettle-3.10.1.bottle_manifest.json\n",
      "==> Pouring nettle--3.10.1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/nettle/3.10.1: 96 files, 2.7MB\n",
      "==> Installing poppler dependency: p11-kit\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/p11-kit/manifests/0.25.5-1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/ba19311d6335b76681ee8e745af9980f80ad52d243a53066a21ead0d6d421a31--p11-kit-0.25.5-1.bottle_manifest.json\n",
      "==> Pouring p11-kit--0.25.5.arm64_sequoia.bottle.1.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/p11-kit/0.25.5: 31 files, 4.2MB\n",
      "==> Installing poppler dependency: openssl@3\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/manifests/3.4.1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/a2bb8b71ebddb1fe8553581fcbc1ffc4ab36795c68b3cd47977cf83f1673a5b1--openssl@3-3.4.1.bottle_manifest.json\n",
      "==> Pouring openssl@3--3.4.1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/openssl@3/3.4.1: 7,236 files, 33.4MB\n",
      "==> Installing poppler dependency: libevent\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libevent/manifests/2.1.12_1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/68b113f9ab63db45f4e1860de522ce2ca4fa081eb3c0d5c7d6005a35c3cf8d06--libevent-2.1.12_1.bottle_manifest.json\n",
      "==> Pouring libevent--2.1.12_1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libevent/2.1.12_1: 58 files, 2.2MB\n",
      "==> Installing poppler dependency: libnghttp2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/manifests/1.65.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/5a72fb9f57dd728c5d6d30917849ae15111c3b440595f5694738ec9434c12427--libnghttp2-1.65.0.bottle_manifest.json\n",
      "==> Pouring libnghttp2--1.65.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libnghttp2/1.65.0: 14 files, 767KB\n",
      "==> Installing poppler dependency: unbound\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/unbound/manifests/1.22.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/94cb5ac77fe9ed3d8e9754f9abb482ea9c14403d0c80616f4f280ed4d7b69496--unbound-1.22.0.bottle_manifest.json\n",
      "==> Pouring unbound--1.22.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/unbound/1.22.0: 59 files, 6MB\n",
      "==> Installing poppler dependency: gnutls\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnutls/manifests/3.8.4\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/73c18cc76ca68c25efa04b897881358a5ad032ae8e54f9c5fe81b70875128236--gnutls-3.8.4.bottle_manifest.json\n",
      "==> Pouring gnutls--3.8.4.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/gnutls/3.8.4: 1,293 files, 10.8MB\n",
      "==> Installing poppler dependency: libgpg-error\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgpg-error/manifests/1.51\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/e7b7f2687086f9cee941cfee0b9d8c83d606b04d85698c55b10eb7a17d2c6bd2--libgpg-error-1.51.bottle_manifest.json\n",
      "==> Pouring libgpg-error--1.51.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libgpg-error/1.51: 50 files, 1.7MB\n",
      "==> Installing poppler dependency: libassuan\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libassuan/manifests/3.0.2\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/0fcd4af28064aef7277b774e3698e36630214907b803972d6722ec02a47a59cd--libassuan-3.0.2.bottle_manifest.json\n",
      "==> Pouring libassuan--3.0.2.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libassuan/3.0.2: 18 files, 566.8KB\n",
      "==> Installing poppler dependency: libgcrypt\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libgcrypt/manifests/1.11.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/1a97cffc3d55ded961cbc89c68edd680c5b12b816a2fc19e30ff3f7cece070e6--libgcrypt-1.11.0.bottle_manifest.json\n",
      "==> Pouring libgcrypt--1.11.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libgcrypt/1.11.0: 24 files, 3.7MB\n",
      "==> Installing poppler dependency: libksba\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libksba/manifests/1.6.7\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/ecb8094d7fe13fc2fed0b4855e73ea116bf776cccef325e58e014fe31d962108--libksba-1.6.7.bottle_manifest.json\n",
      "==> Pouring libksba--1.6.7.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libksba/1.6.7: 19 files, 529.8KB\n",
      "==> Installing poppler dependency: libusb\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libusb/manifests/1.0.27\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/55f37930c4e678b6d2cd789c12b59fc9ec1784ecd5c034e3ea54721c7f32272b--libusb-1.0.27.bottle_manifest.json\n",
      "==> Pouring libusb--1.0.27.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libusb/1.0.27: 23 files, 619.7KB\n",
      "==> Installing poppler dependency: npth\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/npth/manifests/1.8\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/4628473efb57fb8665d271a0d6c96c69b2d6ef2ce61fe0ac620c7efc2dbc7512--npth-1.8.bottle_manifest.json\n",
      "==> Pouring npth--1.8.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/npth/1.8: 13 files, 168.7KB\n",
      "==> Installing poppler dependency: pinentry\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pinentry/manifests/1.3.1_1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/617908cf1b83df85f8782c945baac7ee7d9941c93a1e3a09d34ba82bacd91460--pinentry-1.3.1_1.bottle_manifest.json\n",
      "==> Pouring pinentry--1.3.1_1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/pinentry/1.3.1_1: 13 files, 457.9KB\n",
      "==> Installing poppler dependency: readline\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/readline/manifests/8.2.13\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/aa1afa38997a2866d91c81fdda8b36d436cd4ea7a82aed07d13c83c56eb3460e--readline-8.2.13.bottle_manifest.json\n",
      "==> Pouring readline--8.2.13.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/readline/8.2.13: 51 files, 1.7MB\n",
      "==> Installing poppler dependency: gnupg\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gnupg/manifests/2.4.7\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/6c3ae00dad22ab427b2646a49159dc14299ac8f924e1557f98acc0f7f7500e48--gnupg-2.4.7.bottle_manifest.json\n",
      "==> Pouring gnupg--2.4.7.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/gnupg/2.4.7: 145 files, 14.8MB\n",
      "==> Installing poppler dependency: gpgme\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/gpgme/manifests/1.24.2\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/b27e679213b6f16659cc6b431f4d7c29bc643a317e9878028545379b1cf08ec0--gpgme-1.24.2.bottle_manifest.json\n",
      "==> Pouring gpgme--1.24.2.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/gpgme/1.24.2: 110 files, 4.8MB\n",
      "==> Installing poppler dependency: jpeg-turbo\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/jpeg-turbo/manifests/3.1.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/6a56a664f24b0435ac129cb33185ae84d884e0f2357ac6fd37727dad9ac5c7d7--jpeg-turbo-3.1.0.bottle_manifest.json\n",
      "==> Pouring jpeg-turbo--3.1.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/jpeg-turbo/3.1.0: 47 files, 3.5MB\n",
      "==> Installing poppler dependency: xz\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/xz/manifests/5.6.4\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/d14e84095418591f4112922f1a834dbac6c7e4fdc334eae0aaff35e2b860cc5b--xz-5.6.4.bottle_manifest.json\n",
      "==> Pouring xz--5.6.4.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/xz/5.6.4: 96 files, 2.0MB\n",
      "==> Installing poppler dependency: lz4\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/manifests/1.10.0-1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/8e11e90eb21a06e0f199af9d80e011e3693c77dd353b2477579d95c8471a5802--lz4-1.10.0-1.bottle_manifest.json\n",
      "==> Pouring lz4--1.10.0.arm64_sequoia.bottle.1.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/lz4/1.10.0: 24 files, 713.6KB\n",
      "==> Installing poppler dependency: zstd\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/manifests/1.5.7\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/596a67b1677f62a8e24e6fdfa7c879891221cb8261242f4355fb4deff1a2ec39--zstd-1.5.7.bottle_manifest.json\n",
      "==> Pouring zstd--1.5.7.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/zstd/1.5.7: 32 files, 2.2MB\n",
      "==> Installing poppler dependency: libtiff\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libtiff/manifests/4.7.0-1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/cc8add3c5369d6c22906554ebc395ebe89f1ac410112bd65bc6d286d4e02f210--libtiff-4.7.0-1.bottle_manifest.json\n",
      "==> Pouring libtiff--4.7.0.arm64_sequoia.bottle.1.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libtiff/4.7.0: 486 files, 8.4MB\n",
      "==> Installing poppler dependency: little-cms2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/little-cms2/manifests/2.17\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/0e5e5ac9e1df07ae001662a85a70b344b31345897c284172f14874c9d329cb85--little-cms2-2.17.bottle_manifest.json\n",
      "==> Pouring little-cms2--2.17.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/little-cms2/2.17: 23 files, 1.4MB\n",
      "==> Installing poppler dependency: nspr\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nspr/manifests/4.36\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/2dc0119ad361ddee3aa46221becf78cfc2c1e4fd9d1cd3ac8d6481f4dbaed304--nspr-4.36.bottle_manifest.json\n",
      "==> Pouring nspr--4.36.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/nspr/4.36: 82 files, 1.2MB\n",
      "==> Installing poppler dependency: nss\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/nss/manifests/3.109\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/356d261a58db67b127a106be0110a8a2e486a900ffdb3c850bc65e0e06713d86--nss-3.109.bottle_manifest.json\n",
      "==> Pouring nss--3.109.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/nss/3.109: 215 files, 19.5MB\n",
      "==> Installing poppler dependency: openjpeg\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/openjpeg/manifests/2.5.3\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/05e309d0892898d6a89fd896da03119707c403fd4cc6877860ec46b66b0946e9--openjpeg-2.5.3.bottle_manifest.json\n",
      "==> Pouring openjpeg--2.5.3.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/openjpeg/2.5.3: 543 files, 14.5MB\n",
      "==> Installing poppler\n",
      "==> Pouring poppler--25.03.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/poppler/25.03.0: 443 files, 30MB\n",
      "==> Running `brew cleanup poppler`...\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "==> Installing dependencies for tesseract: graphite2, icu4c@76, harfbuzz, giflib, webp, leptonica, libb2, libarchive, fribidi and pango\n",
      "==> Installing tesseract dependency: graphite2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/graphite2/manifests/1.3.14\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/bbb4dd2ef1846301d1eb08053e19e11ca9c780f93f4d3b2d638fd94a9bf54a0c--graphite2-1.3.14.bottle_manifest.json\n",
      "==> Pouring graphite2--1.3.14.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/graphite2/1.3.14: 19 files, 284.8KB\n",
      "==> Installing tesseract dependency: icu4c@76\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/icu4c/76/manifests/76.1_1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/c105f8980d3a6b0ff0253b47492e886520580406ee75fa52509cf5b251b4d633--icu4c@76-76.1_1.bottle_manifest.json\n",
      "==> Pouring icu4c@76--76.1_1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/icu4c@76/76.1_1: 277 files, 81MB\n",
      "==> Installing tesseract dependency: harfbuzz\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/harfbuzz/manifests/10.4.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/b7209e28b6339dd7642dda11883c4a5c99facd09fba5dd584fe5517b74ae9d6e--harfbuzz-10.4.0.bottle_manifest.json\n",
      "==> Pouring harfbuzz--10.4.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/harfbuzz/10.4.0: 77 files, 9.9MB\n",
      "==> Installing tesseract dependency: giflib\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/giflib/manifests/5.2.2\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/283773c4d2db4fe867419d7eea6811a6417889d78fad8871041c07f49b22d2a1--giflib-5.2.2.bottle_manifest.json\n",
      "==> Pouring giflib--5.2.2.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/giflib/5.2.2: 20 files, 546.9KB\n",
      "==> Installing tesseract dependency: webp\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/webp/manifests/1.5.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/674b427392a0b30f8c95a3047f8d8b59cc729067bec5e51403e4bb87e009102a--webp-1.5.0.bottle_manifest.json\n",
      "==> Pouring webp--1.5.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/webp/1.5.0: 64 files, 2.5MB\n",
      "==> Installing tesseract dependency: leptonica\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/leptonica/manifests/1.85.0\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/2320341c42605b3b080a8ba021dfdc6e3604906b772b77ad098897c13f8f3186--leptonica-1.85.0.bottle_manifest.json\n",
      "==> Pouring leptonica--1.85.0.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/leptonica/1.85.0: 57 files, 6.9MB\n",
      "==> Installing tesseract dependency: libb2\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libb2/manifests/0.98.1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/9bb23dca331f0d74876fa5c769113885b92af8a741a851cdfe99f6dfd420b12d--libb2-0.98.1.bottle_manifest.json\n",
      "==> Pouring libb2--0.98.1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libb2/0.98.1: 9 files, 128.9KB\n",
      "==> Installing tesseract dependency: libarchive\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/libarchive/manifests/3.7.7\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/db913cd1183c4958a5c52ed8d1ea4fd89360b33d164c5a2380c504954f26108c--libarchive-3.7.7.bottle_manifest.json\n",
      "==> Pouring libarchive--3.7.7.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libarchive/3.7.7: 65 files, 3.8MB\n",
      "==> Installing tesseract dependency: fribidi\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/fribidi/manifests/1.0.16\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/9b4a81e7d1c2fe7c2d8ed4194565744f65bab0238c00f7f3f521f5aec2b8697f--fribidi-1.0.16.bottle_manifest.json\n",
      "==> Pouring fribidi--1.0.16.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/fribidi/1.0.16: 68 files, 568.0KB\n",
      "==> Installing tesseract dependency: pango\n",
      "==> Downloading https://ghcr.io/v2/homebrew/core/pango/manifests/1.56.1\n",
      "Already downloaded: /Users/vamanmalik/Library/Caches/Homebrew/downloads/75e1e6e5c9a7d9f4128b8a936564740ec555add0e80ba8ec1830271c72a675e1--pango-1.56.1.bottle_manifest.json\n",
      "==> Pouring pango--1.56.1.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/pango/1.56.1: 69 files, 3.4MB\n",
      "==> Installing tesseract\n",
      "==> Pouring tesseract--5.5.0.arm64_sequoia.bottle.tar.gz\n",
      "==> Caveats\n",
      "This formula contains only the \"eng\", \"osd\", and \"snum\" language data files.\n",
      "If you need any other supported languages, run `brew install tesseract-lang`.\n",
      "==> Summary\n",
      "🍺  /opt/homebrew/Cellar/tesseract/5.5.0: 75 files, 33MB\n",
      "==> Running `brew cleanup tesseract`...\n",
      "==> Pouring libmagic--5.46.arm64_sequoia.bottle.tar.gz\n",
      "🍺  /opt/homebrew/Cellar/libmagic/5.46: 360 files, 12.1MB\n",
      "==> Running `brew cleanup libmagic`...\n",
      "==> Caveats\n",
      "==> tesseract\n",
      "This formula contains only the \"eng\", \"osd\", and \"snum\" language data files.\n",
      "If you need any other supported languages, run `brew install tesseract-lang`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='/opt/homebrew/bin/brew install poppler tesseract libmagic', returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2nDWBTrhn-_M",
   "metadata": {
    "id": "2nDWBTrhn-_M",
    "outputId": "7f1e98ab-538a-4c49-85ef-8590f83c4770",
    "ExecuteTime": {
     "end_time": "2025-03-09T08:50:01.514045Z",
     "start_time": "2025-03-09T08:48:53.469403Z"
    }
   },
   "source": [
    "%pip install -Uq \"unstructured[all-docs]\" pillow lxml pillow\n",
    "%pip install -Uq chromadb tiktoken\n",
    "%pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
    "%pip install -Uq python_dotenv\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "91106e31",
   "metadata": {
    "id": "91106e31",
    "outputId": "fb35d92c-c338-4b78-bacb-5da648093f6e",
    "ExecuteTime": {
     "end_time": "2025-03-09T08:50:05.466043Z",
     "start_time": "2025-03-09T08:50:05.463458Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# keys for the services we will use\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4",
   "metadata": {
    "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4"
   },
   "source": [
    "## Extract the data\n",
    "\n",
    "Extract the elements of the PDF that we will be able to use in the retrieval process. These elements can be: Text, Images, Tables, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ec070",
   "metadata": {
    "id": "e62ec070"
   },
   "source": [
    "### Partition PDF tables, text, and images"
   ]
  },
  {
   "cell_type": "code",
   "id": "0a046528-8d22-4f4e-a520-962026562939",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308,
     "referenced_widgets": [
      "5246faf4e8194647a4b41d9de5a168f6",
      "c8f31460d7d5420db2c7840e287fac5b",
      "2ee43f14fa654a66ad0cfb559826f266",
      "e7e6388db19d47ceb06afc75fbb8486c",
      "922be25533bd448e9ce92614f7bd2677",
      "f63ee7f4234c45d48829e011f24eafde",
      "f8bcfb1381aa46d89034ea50e30b43cf",
      "00b164fb36864e53a8a73710d7d855cc",
      "64a0c4aa0bba4b6f8e8f5775a4341147",
      "2bcca7acc6f047d6ad4efbf1e5333c58",
      "052ec73371404595b7dec973dda308d4",
      "b12ba9f2111c44eeb5ae65820cc7d5d7",
      "15b9261bb07f4bbb95d276b92feabade",
      "5ffb0b594f51466284af380fd4d47b40",
      "fc994e0c5ced45c78c0b9bb6f19c073f",
      "c58471c60519419e9cdb3c7ff174d702",
      "0e7ed203dde24ec9a8d0f9c95a8877fd",
      "e64cfd87330d4b238596da66db63d984",
      "c13aff2b064743be941b4672550e56c9",
      "ef5fba5f330748faa9bd583d637087a6",
      "daabde9b4b764797af6b96370e40c1d2",
      "7d37b6f0ba8b4c5eb875635b98778d26",
      "a9a67e81e91e46e19b23f58dea634525",
      "2045ffddb5c4407f9235d1bf472e9ba5",
      "2df0c4cc59044ec8a59aadf2d5d2a9c9",
      "3095817ccc8f4ec6bae9b0c201d8e40a",
      "93205e664daa4921959605eb99dfa9cc",
      "9eab400a02dc46269e2537db44a78625",
      "415ddcb74bc2467fa9399039b7d0cafb",
      "b2fc825e7e6949e0a18f491ff261ac2b",
      "df6e6c84cc1c4c7b8cf5f8555eb42166",
      "547eb1582628438c9f0ef01554dfcdb4",
      "40b532d4d85740a2a16251bb321f489a",
      "ef897646c62444929b91935d3917b14d",
      "3bd05fe4e6bd4ea2b7bfcfba705369c5",
      "27e36e7f92d7417bb221fa95406cfb2f",
      "21318da3ae0644c28ec63983a34bd2ee",
      "c428c0bd915d455986b3193e9636ea80",
      "01ef4b60c3144e17afffb86281466bab",
      "3494ef9884224fa9a0a65999d7fc2945",
      "7185b40a7fa74088ad7ff6efb524e6b5",
      "cc6672c78dac468d9264efd90902c87d",
      "7ad056a7d71847d498f270ecac5cbf62",
      "309bad22d08c47af8d51942da599328e"
     ]
    },
    "id": "0a046528-8d22-4f4e-a520-962026562939",
    "outputId": "85bfb6b1-557f-4d4d-be94-b0c7200150e2",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T09:11:25.196234Z",
     "start_time": "2025-03-09T09:10:44.647494Z"
    }
   },
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "output_path = \"./content/\"\n",
    "file_path = output_path + 'attention.pdf'\n",
    "\n",
    "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
    "chunks = partition_pdf(\n",
    "    filename=file_path,\n",
    "    infer_table_structure=True,            # extract tables\n",
    "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",          # or 'basic'\n",
    "    max_characters=10000,                  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,       # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "\n",
    "    # extract_images_in_pdf=True,          # deprecated\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:27.205283Z",
     "start_time": "2025-03-09T09:19:47.489634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Explicitly set the Poppler path for PyCharm\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\"\n",
    "\n",
    "output_path = \"./content/\"\n",
    "file_path = output_path + 'attention.pdf'\n",
    "\n",
    "chunks = partition_pdf(\n",
    "    filename=file_path,\n",
    "    infer_table_structure=True,            # extract tables\n",
    "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",          # or 'basic'\n",
    "    max_characters=10000,                  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,       # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    ")"
   ],
   "id": "ed72a1616bc7e650",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "038f6733",
   "metadata": {
    "id": "038f6733",
    "outputId": "9645206b-5b1d-45b5-ae1d-1883d78247f6",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:29.067693Z",
     "start_time": "2025-03-09T09:20:29.064705Z"
    }
   },
   "source": [
    "# We get 2 types of elements from the partition_pdf function\n",
    "set([str(type(el)) for el in chunks])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "cccca0db",
   "metadata": {
    "id": "cccca0db",
    "outputId": "46f33bf2-d1d8-4bef-a0bf-d903ae2179d3",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:30.073120Z",
     "start_time": "2025-03-09T09:20:30.070549Z"
    }
   },
   "source": [
    "# Each CompositeElement containes a bunch of related elements.\n",
    "# This makes it easy to use these elements together in a RAG pipeline.\n",
    "\n",
    "chunks[3].metadata.orig_elements"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x3215dad10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363811710>,\n",
       " <unstructured.documents.elements.Footer at 0x363813650>,\n",
       " <unstructured.documents.elements.Title at 0x332d0ab90>,\n",
       " <unstructured.documents.elements.Title at 0x3323f3a10>,\n",
       " <unstructured.documents.elements.Image at 0x363813a90>,\n",
       " <unstructured.documents.elements.Image at 0x363810950>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363810d10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363811e50>,\n",
       " <unstructured.documents.elements.Title at 0x363812190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363813c50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363813050>,\n",
       " <unstructured.documents.elements.Formula at 0x363813dd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3638107d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x363812390>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "b8766f03",
   "metadata": {
    "id": "b8766f03",
    "outputId": "8bd43211-e0a6-4d35-833e-ee7cb374c9b6",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:32.206698Z",
     "start_time": "2025-03-09T09:20:32.203542Z"
    }
   },
   "source": [
    "# This is what an extracted image looks like.\n",
    "# It contains the base64 representation only because we set the param extract_image_block_to_payload=True\n",
    "\n",
    "elements = chunks[3].metadata.orig_elements\n",
    "chunk_images = [el for el in elements if 'Image' in str(type(el))]\n",
    "chunk_images[0].to_dict()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'element_id': '24c674e0-5e83-4d10-aac8-e00d42f64193',\n",
       " 'text': '',\n",
       " 'metadata': {'coordinates': {'points': ((486.0, 261.1805555555558),\n",
       "    (486.0, 614.7805555555556),\n",
       "    (664.0, 614.7805555555556),\n",
       "    (664.0, 261.1805555555558)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1700,\n",
       "   'layout_height': 2200},\n",
       "  'last_modified': '2024-12-01T19:06:14',\n",
       "  'filetype': 'PPM',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 4,\n",
       "  'image_base64': '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',\n",
       "  'image_mime_type': 'image/jpeg'}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "id": "26caebda",
   "metadata": {
    "id": "26caebda"
   },
   "source": [
    "### Separate extracted elements into tables, text, and images"
   ]
  },
  {
   "cell_type": "code",
   "id": "8326a750",
   "metadata": {
    "id": "8326a750",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:34.440196Z",
     "start_time": "2025-03-09T09:20:34.437768Z"
    }
   },
   "source": [
    "# separate tables from texts\n",
    "tables = []\n",
    "texts = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    if \"Table\" in str(type(chunk)):\n",
    "        tables.append(chunk)\n",
    "\n",
    "    if \"CompositeElement\" in str(type((chunk))):\n",
    "        texts.append(chunk)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "df548e46",
   "metadata": {
    "id": "df548e46",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:35.588441Z",
     "start_time": "2025-03-09T09:20:35.585887Z"
    }
   },
   "source": [
    "# Get the images from the CompositeElement objects\n",
    "def get_images_base64(chunks):\n",
    "    images_b64 = []\n",
    "    for chunk in chunks:\n",
    "        if \"CompositeElement\" in str(type(chunk)):\n",
    "            chunk_els = chunk.metadata.orig_elements\n",
    "            for el in chunk_els:\n",
    "                if \"Image\" in str(type(el)):\n",
    "                    images_b64.append(el.metadata.image_base64)\n",
    "    return images_b64\n",
    "\n",
    "images = get_images_base64(chunks)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "9582f462",
   "metadata": {
    "id": "9582f462"
   },
   "source": [
    "#### Check what the images look like"
   ]
  },
  {
   "cell_type": "code",
   "id": "83158c36",
   "metadata": {
    "id": "83158c36",
    "outputId": "50ba7432-e879-4a64-e9f4-b47fdbeb0fbf",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:37.642099Z",
     "start_time": "2025-03-09T09:20:37.638376Z"
    }
   },
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def display_base64_image(base64_code):\n",
    "    # Decode the base64 string to binary\n",
    "    image_data = base64.b64decode(base64_code)\n",
    "    # Display the image\n",
    "    display(Image(data=image_data))\n",
    "\n",
    "display_base64_image(images[0])"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf",
   "metadata": {
    "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf"
   },
   "source": [
    "## Summarize the data\n",
    "\n",
    "Create a summary of each element extracted from the PDF. This summary will be vectorized and used in the retrieval process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55862c",
   "metadata": {
    "id": "8b55862c"
   },
   "source": [
    "### Text and Table summaries\n",
    "\n",
    "We don't need a multimodal model to generate the summaries of the tables and the text. I will use open source models available on Groq."
   ]
  },
  {
   "cell_type": "code",
   "id": "08b3d2bc",
   "metadata": {
    "id": "08b3d2bc",
    "outputId": "5c39beb3-2a0c-44b8-c2b2-48a4e451282c",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:12:59.513828Z",
     "start_time": "2025-03-09T09:12:57.090563Z"
    }
   },
   "source": [
    "%pip install -Uq langchain-groq"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "523e6ed2-2132-4748-bdb7-db765f20648d",
   "metadata": {
    "id": "523e6ed2-2132-4748-bdb7-db765f20648d",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:42.601895Z",
     "start_time": "2025-03-09T09:20:42.599817Z"
    }
   },
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99",
   "metadata": {
    "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:44.297168Z",
     "start_time": "2025-03-09T09:20:44.264712Z"
    }
   },
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"\n",
    "You are an assistant tasked with summarizing tables and text.\n",
    "Give a concise summary of the table or text.\n",
    "\n",
    "Respond only with the summary, no additionnal comment.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give the summary as it is.\n",
    "\n",
    "Table or text chunk: {element}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary chain\n",
    "model = ChatGroq(temperature=0.5, model=\"llama-3.1-8b-instant\")\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "f176b374-aef0-48f4-a104-fb26b1dd6922",
   "metadata": {
    "id": "f176b374-aef0-48f4-a104-fb26b1dd6922",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:48.251154Z",
     "start_time": "2025-03-09T09:20:46.798991Z"
    }
   },
   "source": [
    "# Summarize text\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 3})\n",
    "\n",
    "# Summarize tables\n",
    "tables_html = [table.metadata.text_as_html for table in tables]\n",
    "table_summaries = summarize_chain.batch(tables_html, {\"max_concurrency\": 3})"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "1d172ad2",
   "metadata": {
    "id": "1d172ad2",
    "outputId": "1ba65afb-c9cd-4503-c154-db7841dfc1d4",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:50.041864Z",
     "start_time": "2025-03-09T09:20:50.038956Z"
    }
   },
   "source": [
    "text_summaries"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Transformer model, proposed by Google Brain, is a simple neural network architecture based on attention mechanisms, replacing traditional recurrent or convolutional networks. It achieves state-of-the-art results in machine translation tasks, including a 28.4 BLEU score on the WMT 2014 English-to-German task and a 41.8 BLEU score on the WMT 2014 English-to-French task.',\n",
       " 'Recurrent neural networks are the state-of-the-art approach in sequence modeling, but have limitations in parallelization. Attention mechanisms have improved sequence modeling, but typically rely on recurrent networks. This work proposes the Transformer, a model that uses attention mechanisms without recurrence, allowing for more parallelization and achieving state-of-the-art translation quality in a short training time.',\n",
       " 'The Transformer model architecture consists of an encoder-decoder structure with stacked self-attention and feed-forward layers. The encoder maps input sequences to continuous representations, while the decoder generates output sequences one element at a time, using multi-head attention and feed-forward networks with residual connections and layer normalization.',\n",
       " 'An attention function maps a query and key-value pairs to an output, computed as a weighted sum of values based on their compatibility with the query. The Scaled Dot-Product Attention function is used, which scales dot products by √dk and applies a softmax function to obtain weights. This is more efficient than additive attention, but can be less effective for large key dimensions.',\n",
       " 'Multi-head attention involves projecting queries, keys, and values h times with learned linear projections, then performing attention in parallel, and concatenating output values. This allows the model to jointly attend to information from different representation subspaces at different positions.',\n",
       " 'The transformer model uses a feed-forward network with two linear transformations and ReLU activation in each layer, applied separately to each position. It uses learned embeddings to convert input and output tokens to vectors, and shares weight matrices between embedding layers and the pre-softmax linear transformation. Positional encodings, represented by sine and cosine functions of different frequencies, are added to input embeddings to inject information about the relative or absolute position of tokens in the sequence.',\n",
       " 'Self-attention layers have lower total computational complexity and more parallelizable computation than recurrent layers, making them faster for sequences with smaller representation dimensionality than length. They also have shorter paths between long-range dependencies, improving ability to learn such dependencies.',\n",
       " 'The training regime for the models consists of 5 components: training data and batching, hardware and schedule, optimizer, regularization, and evaluation. The training data includes the WMT 2014 English-German and English-French datasets, with a shared vocabulary of 37,000 tokens for English-German and a 32,000 word-piece vocabulary for English-French. The models were trained on 8 NVIDIA P100 GPUs, with the base model taking 0.4 seconds per step and the big model taking 1.0 second per step. The Adam optimizer was used with a learning rate formula that increases linearly for the first 4,000 steps and decreases proportionally to the inverse square root of the step number thereafter. Three types of regularization were employed: residual dropout, label smoothing, and weight decay.',\n",
       " 'The big transformer model achieves a new state-of-the-art BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.0 on the English-to-French task, outperforming previously published models at a fraction of the training cost.',\n",
       " 'The Transformer model generalizes well to English constituency parsing, achieving state-of-the-art results in small-data regimes. It outperforms previous models, including RNN sequence-to-sequence models and the Berkeley-Parser, even when trained on a small dataset of 40K sentences. The model performs particularly well in a semi-supervised setting, achieving a F1 score of 92.7.',\n",
       " 'The Transformer model, based on attention, replaces recurrent layers and achieves a new state-of-the-art in translation tasks, outperforming ensembles on WMT 2014 English-to-German and English-to-French tasks.',\n",
       " 'This text discusses neural machine translation and computer vision, citing several papers including \"Rethinking the Inception Architecture for Computer Vision\" and \"Google\\'s Neural Machine Translation System\". It also includes visualizations of attention mechanisms, specifically self-attention in layer 5 of 6, which attend to distant dependencies and exhibit behavior related to sentence structure.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1",
   "metadata": {
    "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1"
   },
   "source": [
    "### Image summaries\n",
    "\n",
    "We will use gpt-4o-mini to produce the image summaries."
   ]
  },
  {
   "cell_type": "code",
   "id": "32c825e1",
   "metadata": {
    "id": "32c825e1",
    "outputId": "3ef8d057-2214-41e8-80e1-c5f902a01ac8",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:20:56.072704Z",
     "start_time": "2025-03-09T09:20:54.721731Z"
    }
   },
   "source": [
    "%pip install -Uq langchain_openai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182",
   "metadata": {
    "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:05.805733Z",
     "start_time": "2025-03-09T09:20:57.099500Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = \"\"\"Describe the image in detail. For context,\n",
    "                  the image is part of a research paper explaining the transformers\n",
    "                  architecture. Be specific about graphs, such as bar plots.\"\"\"\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": prompt_template},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "\n",
    "image_summaries = chain.batch(images)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "laF_8o1gzHT0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laF_8o1gzHT0",
    "outputId": "f82547af-0885-4d78-9f50-940dd9e6551e",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:07.293422Z",
     "start_time": "2025-03-09T09:21:07.290372Z"
    }
   },
   "source": [
    "image_summaries"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The image illustrates the architecture of a transformer model, which is a crucial framework in natural language processing. Here’s a detailed description of its components:\\n\\n1. **Structure**: The diagram is organized into two main sections: the encoder on the left and the decoder on the right, both featuring stacks of layers (denoted as \\\\(N_x\\\\)), suggesting that these layers can be repeated multiple times.\\n\\n2. **Encoder**:\\n   - The left side shows the encoder block in which each layer consists of:\\n     - **Multi-Head Attention**: This component allows the model to focus on multiple parts of the input simultaneously. It includes a normalization step labeled as \"Add & Norm\" to ensure that the subsequent layers maintain balanced gradients.\\n     - **Feed Forward**: Following the attention mechanism, the encoder includes a feed-forward neural network that processes the features extracted from the attention mechanism, again followed by \"Add & Norm\".\\n\\n3. **Decoder**:\\n   - The right side depicts the decoder, which also contains multiple layers with a similar structure to the encoder but incorporates additional components:\\n     - **Masked Multi-Head Attention**: This is a variant of the multi-head attention that prevents the decoder from attending to future tokens, ensuring that the prediction for a certain token is not influenced by subsequent tokens.\\n     - The decoder also connects to the input through an additional \"Add & Norm\", followed by the feed-forward mechanism.\\n\\n4. **Input and Output**:\\n   - **Input Embedding**: At the bottom, the encoder receives the input embeddings combined with positional encoding to retain the order of input tokens.\\n   - **Output (shifted right)**: Similarly, the decoder processes output embeddings that are also combined with positional encoding. This indicates that the output generation is based on previous outputs.\\n\\n5. **Final Layer**:\\n   - At the top of the whole architecture, a \"Linear\" layer leads to a \"Softmax\" output layer, which produces output probabilities, typically representing the likelihood of each possible next token in the sequence.\\n\\n6. **Positional Encoding**: There are symbols indicating positional encoding, crucial for maintaining the sequence of input data through the architecture.\\n\\nOverall, this diagram is a comprehensive representation of how transformers process input data through encoded and decoded layers, utilizing attention mechanisms and feed-forward networks for tasks such as translation, text summarization, and more.',\n",
       " 'The image depicts a flowchart that illustrates a component of the transformer architecture, specifically the attention mechanism. \\n\\n1. **Structure**: The flowchart consists of several labeled boxes arranged vertically, indicating the sequence of operations in the attention block.\\n\\n2. **Boxes and Operations**:\\n   - At the top, there is a box labeled \"MatMul,\" indicating a matrix multiplication operation. This is usually associated with the dot product of queries (Q) and keys (K).\\n   - Below this is a box labeled \"SoftMax,\" which indicates the application of the softmax function. This operation is important for normalizing the attention scores.\\n   - Below that is an optional operation represented by a box labeled \"Mask,\" suggesting that a masking operation can be applied, commonly used during training to prevent certain positions from affecting others.\\n   - Further down, there is a box labeled \"Scale,\" which usually refers to scaling the attention scores, typically by the square root of the dimension of the keys.\\n   - The lowest box labeled \"MatMul\" indicates another matrix multiplication, this time involving the output of the softmax (or masked softmax) and the values (V).\\n\\n3. **Arrows**: Arrows connect these operations to illustrate the flow of data through them. The arrows indicate the direction of processing, starting from Q and K inputs leading into the first MatMul operation, and culminating with the output connected to V as the final operation.\\n\\n4. **Color Coding**: The boxes are color-coded, which may signify different types of operations or stages in the process, adding clarity and visual distinction to the components involved in this part of the transformer architecture.\\n\\nOverall, the image effectively summarizes the process of calculating attention scores and generating impactful output within the transformers framework.',\n",
       " 'The image depicts a simplified diagram of the transformer architecture, specifically focusing on the attention mechanism known as \"Scaled Dot-Product Attention.\" \\n\\n### Diagram Elements:\\n\\n1. **Input Components:**\\n   - At the bottom of the diagram, there are three parallel boxes labeled \"Linear\" corresponding to inputs: V (Value), K (Key), and Q (Query). These represent the transformed inputs for the attention mechanism.\\n\\n2. **Attention Mechanism:**\\n   - Above the input components, there is a large purple box labeled \"Scaled Dot-Product Attention.\" This denotes the core function where the attention scores are calculated using the query and key inputs and then applied to the value input.\\n\\n3. **Aggregation:**\\n   - Above the attention mechanism box, there is a yellow box labeled \"Concat.\" This indicates that the outputs from multiple attention heads are concatenated for further processing.\\n\\n4. **Further Processing:**\\n   - Following the concatenation, there’s a flow indicated by arrows leading upwards to another “Linear” layer, suggesting that the concatenated output is passed through another linear transformation for final output.\\n\\n5. **Arrows and Connections:**\\n   - The diagram features multiple arrows connecting the different elements, illustrating the flow of data through each stage of the architecture. The arrows show how the inputs interact with the attention mechanism and how the output is derived.\\n\\nThis diagram essentially encapsulates the main components and flow of data in the attention mechanism of the transformer architecture, highlighting the roles played by the queries, keys, values, and the processing steps that follow.',\n",
       " 'The image appears to represent a visual explanation of the Transformer architecture, likely illustrating the attention mechanism or the relationship between input and output tokens. Here\\'s a detailed breakdown:\\n\\n1. **Tokens**: The left and right sections of the image consist of various tokens (words) arranged vertically. These tokens represent a sequence of words from a text input, including terms like \"making,\" \"majority,\" \"voting,\" and more.\\n\\n2. **Attention Head**: In the center, there is a highlighted focal point around the year \"2009,\" which is likely the primary token that other tokens are attending to. Lines or arrows emanate from this token to others, indicating how the attention mechanism links various parts of the input sequence.\\n\\n3. **Connections**: The arrows connecting the tokens are displayed in different colors, suggesting varying levels of attention weights. The varying thickness and transparency of these lines indicate how much emphasis the model places on certain words relative to others during processing.\\n\\n4. **End Tokens and Padding**: At the far right side, there are tokens that look like \"<EOS>\" (indicating the end of the sequence) and \"<pad>\" (indicating padding used in the input). These are standard in sequence models to denote the boundaries and ensure uniform input lengths.\\n\\n5. **Color Coding**: Some tokens and connections appear to be color-coded or patterned, which may represent different semantic meanings or categories of words within the context of the Transformer model\\'s attention mechanism.\\n\\nOverall, the image visually conveys how the Transformer processes sequences through attention, highlighting token relationships and operational characteristics integral to its functionality.',\n",
       " 'The image illustrates the inner workings of a Transformer model, specifically highlighting the attention mechanism. \\n\\n### Description:\\n1. **Text Tokens**: The image contains a series of tokens, which are words or subwords, arranged in two rows. The tokens represent an input sentence at the top and the corresponding output at the bottom.\\n\\n2. **Connections (Arrows)**: \\n   - **Thick Purple Arrows**: These arrows represent strong attention weights, indicating which tokens in the input influence the output tokens the most. The thickness and color intensity of these arrows convey the strength of the connections between the tokens.\\n   - **Fainter Connections**: There are lighter, thinner connections present as well, illustrating weaker attention weights.\\n\\n3. **Token Representation**: \\n   - The first row contains input tokens like \"The\", \"Law\", \"will\", etc.\\n   - The second row reflects the output structure, including tokens such as \"is\", \"what\", and \"<EOS>\" (End of Sentence).\\n\\n4. **Central Nodes**: Notably, the token \"Law\" in the input section seems to be a focal point, as indicated by its distinct purple background, highlighting its importance in the attention context. \\n\\n5. **Padding Token**: There is a \"<pad>\" token at the far right of the output row, which typically represents padding in sequences to ensure uniform length.\\n\\n### Context:\\nThis visual aids in understanding how different parts of the input sequence (the top row) contribute to the generation of each output token (the bottom row) in a Transformer model, showcasing the core mechanism of attention within the architecture.',\n",
       " 'The image appears to represent a visualization of attention weights in a transformer model, specifically showcasing how words in a sequence relate to one another through directed connections.\\n\\n### Key Features of the Image:\\n\\n1. **Text Components**: \\n   - The image contains several words arranged in two horizontal lines. The left segment includes words like \"The,\" \"Law,\" \"will,\" \"never,\" and \"perfect,\" while the right segment features phrases like \"this,\" \"is,\" \"what,\" \"we,\" \"are,\" \"missing,\" and \"in my opinion.\"\\n\\n2. **Connections**: \\n   - Between these two rows of words, there are multiple lines drawn. The lines vary in thickness and color, primarily green, indicating the strength of the attention weights between corresponding words. Thicker lines suggest stronger relationships or attentional focus, while thinner lines indicate weaker links.\\n   - Some lines connect words from the left to the right and present a complex interrelation, suggesting how each word may influence or relate to others in the context of a task such as language modeling or text generation.\\n\\n3. **Directional Nature**: \\n   - The connections are undirected, indicating a mutual relationship and the potential for both words to influence each other during the processing in the transformer architecture.\\n\\n4. **Special Tokens**:\\n   - At the far right, there are special tokens like `<EOS>` (End Of Sequence) and `<pad>` (Padding), which are commonly used in transformer models to denote the end of input sequences and fill space in sequences of different lengths, respectively.\\n\\nThis visualization can be used to illustrate how transformers utilize attention mechanisms to determine the significance of words in relation to one another, supporting tasks such as language understanding and generation.',\n",
       " 'The image illustrates a part of a transformer architecture, showcasing how attention mechanisms connect individual words in a sequence. \\n\\n### Description:\\n\\n1. **Text Layout**:\\n   - The words are arranged in a linear sequence, displayed in a bold font. \\n   - The sequence includes various words such as \"The,\" \"Law,\" \"never,\" \"perfect,\" \"should,\" \"this,\" and \"missing,\" moving from left to right.\\n\\n2. **Connections**:\\n   - Red and light red lines connect specific words from the left side to those on the right side.\\n   - The darker red lines indicate stronger connections or attention, while the lighter red lines represent weaker connections.\\n   - These lines demonstrate the attention weights calculated for each word, indicating how much focus is given to each word when processing the input.\\n\\n3. **Special Tokens**:\\n   - Toward the end of the sequence, there are special tokens like `<EOS>` (End of Sequence) and `<pad>` (Padding), which are common in natural language processing tasks.\\n\\n4. **Overall Structure**:\\n   - The structure suggests a complex interplay between words, highlighting how some words have multiple connections, reflecting their relevance in different contexts within the same sequence.\\n\\nThis visualization is likely meant to illustrate the principles of self-attention within the transformer architecture, showcasing how each word interacts with every other word to allow for context-aware processing.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "aHNDEd_2txQI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "aHNDEd_2txQI",
    "outputId": "fbd7c64e-f463-4203-e1ca-f79c7426aaf6",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:14.024928Z",
     "start_time": "2025-03-09T09:21:14.022910Z"
    }
   },
   "source": [
    "print(image_summaries[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a flowchart that illustrates a component of the transformer architecture, specifically the attention mechanism. \n",
      "\n",
      "1. **Structure**: The flowchart consists of several labeled boxes arranged vertically, indicating the sequence of operations in the attention block.\n",
      "\n",
      "2. **Boxes and Operations**:\n",
      "   - At the top, there is a box labeled \"MatMul,\" indicating a matrix multiplication operation. This is usually associated with the dot product of queries (Q) and keys (K).\n",
      "   - Below this is a box labeled \"SoftMax,\" which indicates the application of the softmax function. This operation is important for normalizing the attention scores.\n",
      "   - Below that is an optional operation represented by a box labeled \"Mask,\" suggesting that a masking operation can be applied, commonly used during training to prevent certain positions from affecting others.\n",
      "   - Further down, there is a box labeled \"Scale,\" which usually refers to scaling the attention scores, typically by the square root of the dimension of the keys.\n",
      "   - The lowest box labeled \"MatMul\" indicates another matrix multiplication, this time involving the output of the softmax (or masked softmax) and the values (V).\n",
      "\n",
      "3. **Arrows**: Arrows connect these operations to illustrate the flow of data through them. The arrows indicate the direction of processing, starting from Q and K inputs leading into the first MatMul operation, and culminating with the output connected to V as the final operation.\n",
      "\n",
      "4. **Color Coding**: The boxes are color-coded, which may signify different types of operations or stages in the process, adding clarity and visual distinction to the components involved in this part of the transformer architecture.\n",
      "\n",
      "Overall, the image effectively summarizes the process of calculating attention scores and generating impactful output within the transformers framework.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87",
   "metadata": {
    "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87"
   },
   "source": [
    "## Load data and summaries to vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d2379",
   "metadata": {
    "id": "bb4d2379"
   },
   "source": [
    "### Create the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
   "metadata": {
    "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
    "outputId": "c91d7a77-d820-446f-a751-15f5d4668e8f",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:21.298746Z",
     "start_time": "2025-03-09T09:21:20.999789Z"
    }
   },
   "source": [
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/z3zym2ks6z9d38dg7pmsrgbm0000gn/T/ipykernel_5076/3675061537.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
      "/var/folders/_h/z3zym2ks6z9d38dg7pmsrgbm0000gn/T/ipykernel_5076/3675061537.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "2bf26669",
   "metadata": {
    "id": "2bf26669"
   },
   "source": [
    "### Load the summaries and link the to the original data"
   ]
  },
  {
   "cell_type": "code",
   "id": "1792e683",
   "metadata": {
    "id": "1792e683",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:55.086239Z",
     "start_time": "2025-03-09T09:21:53.664737Z"
    }
   },
   "source": [
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n",
    "# Add image summaries\n",
    "img_ids = [str(uuid.uuid4()) for _ in images]\n",
    "summary_img = [\n",
    "    Document(page_content=summary, metadata={id_key: img_ids[i]}) for i, summary in enumerate(image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_img)\n",
    "retriever.docstore.mset(list(zip(img_ids, images)))"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected Embedings to be non-empty list or numpy array, got [] in upsert.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001B[39m, in \u001B[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:389\u001B[39m, in \u001B[36mCollectionCommon._validate_and_prepare_upsert_request\u001B[39m\u001B[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;129m@validation_context\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mupsert\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_validate_and_prepare_upsert_request\u001B[39m(\n\u001B[32m    375\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    387\u001B[39m ) -> UpsertRequest:\n\u001B[32m    388\u001B[39m     \u001B[38;5;66;03m# Unpack\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m     upsert_records = \u001B[43mnormalize_insert_record_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m        \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    398\u001B[39m     \u001B[38;5;66;03m# Validate\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:187\u001B[39m, in \u001B[36mnormalize_insert_record_set\u001B[39m\u001B[34m(ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    184\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    185\u001B[39m \u001B[33;03mUnpacks and normalizes the fields of an InsertRecordSet.\u001B[39;00m\n\u001B[32m    186\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m base_record_set = \u001B[43mnormalize_base_record_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m InsertRecordSet(\n\u001B[32m    192\u001B[39m     ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001B[32m    193\u001B[39m     metadatas=maybe_cast_one_to_many(metadatas),\n\u001B[32m   (...)\u001B[39m\u001B[32m    197\u001B[39m     uris=base_record_set[\u001B[33m\"\u001B[39m\u001B[33muris\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    198\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:164\u001B[39m, in \u001B[36mnormalize_base_record_set\u001B[39m\u001B[34m(embeddings, documents, images, uris)\u001B[39m\n\u001B[32m    159\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    160\u001B[39m \u001B[33;03mUnpacks and normalizes the fields of a BaseRecordSet.\u001B[39;00m\n\u001B[32m    161\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    163\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m BaseRecordSet(\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m     embeddings=\u001B[43mnormalize_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    165\u001B[39m     documents=maybe_cast_one_to_many(documents),\n\u001B[32m    166\u001B[39m     images=maybe_cast_one_to_many(images),\n\u001B[32m    167\u001B[39m     uris=maybe_cast_one_to_many(uris),\n\u001B[32m    168\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:61\u001B[39m, in \u001B[36mnormalize_embeddings\u001B[39m\u001B[34m(target)\u001B[39m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target) == \u001B[32m0\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m     62\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected Embedings to be non-empty list or numpy array, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     63\u001B[39m     )\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m     66\u001B[39m     \u001B[38;5;66;03m# One PyEmbedding\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Expected Embedings to be non-empty list or numpy array, got []",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[69]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     10\u001B[39m table_ids = [\u001B[38;5;28mstr\u001B[39m(uuid.uuid4()) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tables]\n\u001B[32m     11\u001B[39m summary_tables = [\n\u001B[32m     12\u001B[39m     Document(page_content=summary, metadata={id_key: table_ids[i]}) \u001B[38;5;28;01mfor\u001B[39;00m i, summary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(table_summaries)\n\u001B[32m     13\u001B[39m ]\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[43mretriever\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvectorstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_tables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m retriever.docstore.mset(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(table_ids, tables)))\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Add image summaries\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:287\u001B[39m, in \u001B[36mVectorStore.add_documents\u001B[39m\u001B[34m(self, documents, **kwargs)\u001B[39m\n\u001B[32m    285\u001B[39m     texts = [doc.page_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[32m    286\u001B[39m     metadatas = [doc.metadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    288\u001B[39m msg = (\n\u001B[32m    289\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m`add_documents` and `add_texts` has not been implemented \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    290\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfor \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    291\u001B[39m )\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(msg)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:326\u001B[39m, in \u001B[36mChroma.add_texts\u001B[39m\u001B[34m(self, texts, metadatas, ids, **kwargs)\u001B[39m\n\u001B[32m    320\u001B[39m         \u001B[38;5;28mself\u001B[39m._collection.upsert(\n\u001B[32m    321\u001B[39m             embeddings=embeddings_without_metadatas,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m    322\u001B[39m             documents=texts_without_metadatas,\n\u001B[32m    323\u001B[39m             ids=ids_without_metadatas,\n\u001B[32m    324\u001B[39m         )\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_collection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m ids\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/Collection.py:335\u001B[39m, in \u001B[36mCollection.upsert\u001B[39m\u001B[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    310\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mupsert\u001B[39m(\n\u001B[32m    311\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    312\u001B[39m     ids: OneOrMany[ID],\n\u001B[32m   (...)\u001B[39m\u001B[32m    322\u001B[39m     uris: Optional[OneOrMany[URI]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    323\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    324\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001B[39;00m\n\u001B[32m    325\u001B[39m \n\u001B[32m    326\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    333\u001B[39m \u001B[33;03m        None\u001B[39;00m\n\u001B[32m    334\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m335\u001B[39m     upsert_request = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_and_prepare_upsert_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m        \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    344\u001B[39m     \u001B[38;5;28mself\u001B[39m._client._upsert(\n\u001B[32m    345\u001B[39m         collection_id=\u001B[38;5;28mself\u001B[39m.id,\n\u001B[32m    346\u001B[39m         ids=upsert_request[\u001B[33m\"\u001B[39m\u001B[33mids\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    352\u001B[39m         database=\u001B[38;5;28mself\u001B[39m.database,\n\u001B[32m    353\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:93\u001B[39m, in \u001B[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     92\u001B[39m     msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001B[39m, in \u001B[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     87\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001B[32m     89\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     91\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     92\u001B[39m         msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:389\u001B[39m, in \u001B[36mCollectionCommon._validate_and_prepare_upsert_request\u001B[39m\u001B[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;129m@validation_context\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mupsert\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_validate_and_prepare_upsert_request\u001B[39m(\n\u001B[32m    375\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    387\u001B[39m ) -> UpsertRequest:\n\u001B[32m    388\u001B[39m     \u001B[38;5;66;03m# Unpack\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m     upsert_records = \u001B[43mnormalize_insert_record_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m        \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    398\u001B[39m     \u001B[38;5;66;03m# Validate\u001B[39;00m\n\u001B[32m    399\u001B[39m     validate_insert_record_set(record_set=upsert_records)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:187\u001B[39m, in \u001B[36mnormalize_insert_record_set\u001B[39m\u001B[34m(ids, embeddings, metadatas, documents, images, uris)\u001B[39m\n\u001B[32m    171\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mnormalize_insert_record_set\u001B[39m(\n\u001B[32m    172\u001B[39m     ids: OneOrMany[ID],\n\u001B[32m    173\u001B[39m     embeddings: Optional[\n\u001B[32m   (...)\u001B[39m\u001B[32m    182\u001B[39m     uris: Optional[OneOrMany[URI]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    183\u001B[39m ) -> InsertRecordSet:\n\u001B[32m    184\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    185\u001B[39m \u001B[33;03m    Unpacks and normalizes the fields of an InsertRecordSet.\u001B[39;00m\n\u001B[32m    186\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m     base_record_set = \u001B[43mnormalize_base_record_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\u001B[43m=\u001B[49m\u001B[43muris\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    191\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m InsertRecordSet(\n\u001B[32m    192\u001B[39m         ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001B[32m    193\u001B[39m         metadatas=maybe_cast_one_to_many(metadatas),\n\u001B[32m   (...)\u001B[39m\u001B[32m    197\u001B[39m         uris=base_record_set[\u001B[33m\"\u001B[39m\u001B[33muris\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    198\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:164\u001B[39m, in \u001B[36mnormalize_base_record_set\u001B[39m\u001B[34m(embeddings, documents, images, uris)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mnormalize_base_record_set\u001B[39m(\n\u001B[32m    154\u001B[39m     embeddings: Optional[Union[OneOrMany[Embedding], OneOrMany[PyEmbedding]]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    155\u001B[39m     documents: Optional[OneOrMany[Document]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    156\u001B[39m     images: Optional[OneOrMany[Image]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    157\u001B[39m     uris: Optional[OneOrMany[URI]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    158\u001B[39m ) -> BaseRecordSet:\n\u001B[32m    159\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    160\u001B[39m \u001B[33;03m    Unpacks and normalizes the fields of a BaseRecordSet.\u001B[39;00m\n\u001B[32m    161\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m BaseRecordSet(\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m         embeddings=\u001B[43mnormalize_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    165\u001B[39m         documents=maybe_cast_one_to_many(documents),\n\u001B[32m    166\u001B[39m         images=maybe_cast_one_to_many(images),\n\u001B[32m    167\u001B[39m         uris=maybe_cast_one_to_many(uris),\n\u001B[32m    168\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/chromadb/api/types.py:61\u001B[39m, in \u001B[36mnormalize_embeddings\u001B[39m\u001B[34m(target)\u001B[39m\n\u001B[32m     58\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target) == \u001B[32m0\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m     62\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected Embedings to be non-empty list or numpy array, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     63\u001B[39m     )\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m     66\u001B[39m     \u001B[38;5;66;03m# One PyEmbedding\u001B[39;00m\n\u001B[32m     67\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target[\u001B[32m0\u001B[39m], (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target[\u001B[32m0\u001B[39m], \u001B[38;5;28mbool\u001B[39m):\n",
      "\u001B[31mValueError\u001B[39m: Expected Embedings to be non-empty list or numpy array, got [] in upsert."
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700",
   "metadata": {
    "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700"
   },
   "source": [
    "### Check retrieval"
   ]
  },
  {
   "cell_type": "code",
   "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215",
   "metadata": {
    "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:57.493632Z",
     "start_time": "2025-03-09T09:21:56.713508Z"
    }
   },
   "source": [
    "# Retrieve\n",
    "docs = retriever.invoke(\n",
    "    \"who are the authors of the paper?\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "a0290c78",
   "metadata": {
    "id": "a0290c78",
    "outputId": "d19cdecf-c9e6-4b40-f996-06041a7f0ee4",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:21:59.087327Z",
     "start_time": "2025-03-09T09:21:59.084673Z"
    }
   },
   "source": [
    "for doc in docs:\n",
    "    print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
      "\n",
      "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
      "\n",
      "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
      "\n",
      "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
      "\n",
      "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
      "\n",
      "12\n",
      "\n",
      "Attention Visualizations\n",
      "\n",
      "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
      "\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "\n",
      "13\n",
      "\n",
      "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
      "\n",
      "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
      "\n",
      "14\n",
      "\n",
      "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
      "\n",
      "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
      "\n",
      "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "\n",
      "15\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
      "\n",
      "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
      "\n",
      "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
      "\n",
      "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
      "\n",
      "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
      "\n",
      "12\n",
      "\n",
      "Attention Visualizations\n",
      "\n",
      "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
      "\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "\n",
      "13\n",
      "\n",
      "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
      "\n",
      "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
      "\n",
      "14\n",
      "\n",
      "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
      "\n",
      "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
      "\n",
      "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "\n",
      "15\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 Training\n",
      "\n",
      "This section describes the training regime for our models.\n",
      "\n",
      "5.1 Training Data and Batching\n",
      "\n",
      "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source- target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens.\n",
      "\n",
      "5.2 Hardware and Schedule\n",
      "\n",
      "We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days).\n",
      "\n",
      "5.3 Optimizer\n",
      "\n",
      "We used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning rate over the course of training, according to the formula:\n",
      "\n",
      "lrate = d−0.5 model · min(step_num−0.5,step_num · warmup_steps−1.5) (3)\n",
      "\n",
      "This corresponds to increasing the learning rate linearly for the first warmup_steps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmup_steps = 4000.\n",
      "\n",
      "5.4 Regularization\n",
      "\n",
      "We employ three types of regularization during training:\n",
      "\n",
      "7\n",
      "\n",
      "Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\n",
      "\n",
      "Model BLEU EN-DE EN-FR Training Cost (FLOPs) EN-DE EN-FR ByteNet [18] 23.75 Deep-Att + PosUnk [39] 39.2 1.0 · 1020 GNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020 ConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020 MoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020 Deep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020 GNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021 ConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021 Transformer (base model) 27.3 38.1 3.3 · 1018 Transformer (big) 28.4 41.8 2.3 · 1019\n",
      "\n",
      "Residual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of Pdrop = 0.1.\n",
      "\n",
      "Label Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 Training\n",
      "\n",
      "This section describes the training regime for our models.\n",
      "\n",
      "5.1 Training Data and Batching\n",
      "\n",
      "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source- target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens.\n",
      "\n",
      "5.2 Hardware and Schedule\n",
      "\n",
      "We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days).\n",
      "\n",
      "5.3 Optimizer\n",
      "\n",
      "We used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning rate over the course of training, according to the formula:\n",
      "\n",
      "lrate = d−0.5 model · min(step_num−0.5,step_num · warmup_steps−1.5) (3)\n",
      "\n",
      "This corresponds to increasing the learning rate linearly for the first warmup_steps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmup_steps = 4000.\n",
      "\n",
      "5.4 Regularization\n",
      "\n",
      "We employ three types of regularization during training:\n",
      "\n",
      "7\n",
      "\n",
      "Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\n",
      "\n",
      "Model BLEU EN-DE EN-FR Training Cost (FLOPs) EN-DE EN-FR ByteNet [18] 23.75 Deep-Att + PosUnk [39] 39.2 1.0 · 1020 GNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020 ConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020 MoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020 Deep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020 GNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021 ConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021 Transformer (base model) 27.3 38.1 3.3 · 1018 Transformer (big) 28.4 41.8 2.3 · 1019\n",
      "\n",
      "Residual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of Pdrop = 0.1.\n",
      "\n",
      "Label Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "id": "69060724-e390-4dda-8250-5f86025c874a",
   "metadata": {
    "id": "69060724-e390-4dda-8250-5f86025c874a"
   },
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069",
   "metadata": {
    "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:22:05.174966Z",
     "start_time": "2025-03-09T09:22:05.118644Z"
    }
   },
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from base64 import b64decode\n",
    "\n",
    "\n",
    "def parse_docs(docs):\n",
    "    \"\"\"Split base64-encoded images and texts\"\"\"\n",
    "    b64 = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc)\n",
    "            b64.append(doc)\n",
    "        except Exception as e:\n",
    "            text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "\n",
    "def build_prompt(kwargs):\n",
    "\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "\n",
    "    context_text = \"\"\n",
    "    if len(docs_by_type[\"texts\"]) > 0:\n",
    "        for text_element in docs_by_type[\"texts\"]:\n",
    "            context_text += text_element.text\n",
    "\n",
    "    # construct prompt with context (including images)\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
    "\n",
    "    if len(docs_by_type[\"images\"]) > 0:\n",
    "        for image in docs_by_type[\"images\"]:\n",
    "            prompt_content.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessage(content=prompt_content),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt)\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_with_sources = {\n",
    "    \"context\": retriever | RunnableLambda(parse_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnablePassthrough().assign(\n",
    "    response=(\n",
    "        RunnableLambda(build_prompt)\n",
    "        | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
    "outputId": "2edf5f7e-9165-46ef-e710-cc945b78b230",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:22:15.369002Z",
     "start_time": "2025-03-09T09:22:09.609004Z"
    }
   },
   "source": [
    "response = chain.invoke(\n",
    "    \"What is the attention mechanism?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention mechanism is a method that allows a model to focus on specific parts of the input sequence when producing an output. In particular, it helps to encode information from different positions, enabling the model to capture long-distance dependencies and contextual relationships within the data.\n",
      "\n",
      "In the context of the provided information, the attention mechanism operates through several key concepts:\n",
      "\n",
      "1. **Multi-Head Attention**: Instead of using a single attention function, the model projects the queries, keys, and values multiple times (h times) with different, learned linear projections. This allows the model to jointly attend to different information in various subspaces, enhancing its ability to learn complex relationships.\n",
      "\n",
      "2. **Types of Attention**: \n",
      "   - **Encoder-Decoder Attention**: In this layer, the queries come from the previous decoder layer, while the keys and values come from the encoder's output, allowing decoder positions to attend to all encoder positions.\n",
      "   - **Self-Attention**: In self-attention layers, all queries, keys, and values come from the same place (the previous layer's output). Each position in the input can attend to all positions in the previous layer, thus capturing contextual relationships internally.\n",
      "   - **Masked Self-Attention in Decoder**: In the decoder, self-attention layers prevent leftward information flow to maintain the auto-regressive property by masking illegal connections.\n",
      "\n",
      "This approach enhances the model's capability to process sequences effectively, making it especially useful in applications such as machine translation, where understanding the context is crucial.\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:23:09.927173Z",
     "start_time": "2025-03-09T09:23:02.308988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = chain_with_sources.invoke(\n",
    "    \"What is the attention mechanism?\"\n",
    ")\n",
    "\n",
    "print(\"Response:\", response['response'])\n",
    "\n",
    "print(\"\\n\\nContext:\")\n",
    "for text in response['context']['texts']:\n",
    "    print(text.text)\n",
    "    print(\"Page number: \", text.metadata.page_number)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "for image in response['context']['images']:\n",
    "    display_base64_image(image)"
   ],
   "id": "3acc2ef17ff0a964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The attention mechanism is a process used in neural networks, particularly in sequence-to-sequence models, that allows the model to focus on specific parts of the input when producing an output. It enables the model to weigh the importance of different input elements dynamically.\n",
      "\n",
      "In the context of the provided text, the attention mechanism operates through multiple steps:\n",
      "\n",
      "1. **Self-Attention**: In layers of the encoder, every position can attend to all positions from the previous layer. This is particularly significant for understanding the relationships and dependencies in the input sequence.\n",
      "\n",
      "2. **Multi-Head Attention**: Instead of using a single attention function, multiple attention heads (h heads) are utilized. Each head performs attention on different projections of the input queries, keys, and values. This allows the model to jointly attend to different representation subspaces and to capture various dependencies in parallel.\n",
      "\n",
      "3. **Encoder-Decoder Attention**: In the decoder, the queries come from the previous decoder layer while the keys and values come from the encoder's output, allowing the decoder to access all input positions when generating the output.\n",
      "\n",
      "4. **Masked Self-Attention in Decoder**: In the decoder's self-attention layers, mechanisms are employed to prevent the flow of information to the left. This maintains the auto-regressive property of the decoder, ensuring that predictions are made based only on previously generated output.\n",
      "\n",
      "Overall, the attention mechanism enhances the model's ability to handle long-distance dependencies and improve the quality of outputs, as it gives the model a flexible way to prioritize relevant information from the input.\n",
      "\n",
      "\n",
      "Context:\n",
      "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
      "\n",
      "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
      "\n",
      "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
      "\n",
      "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
      "\n",
      "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
      "\n",
      "12\n",
      "\n",
      "Attention Visualizations\n",
      "\n",
      "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
      "\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "\n",
      "13\n",
      "\n",
      "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
      "\n",
      "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
      "\n",
      "14\n",
      "\n",
      "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
      "\n",
      "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
      "\n",
      "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "\n",
      "15\n",
      "Page number:  12\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
      "\n",
      "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
      "\n",
      "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
      "\n",
      "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
      "\n",
      "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
      "\n",
      "12\n",
      "\n",
      "Attention Visualizations\n",
      "\n",
      "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
      "\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "\n",
      "13\n",
      "\n",
      "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
      "\n",
      "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
      "\n",
      "14\n",
      "\n",
      "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
      "\n",
      "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
      "\n",
      "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "\n",
      "15\n",
      "Page number:  12\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "Page number:  4\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "Page number:  4\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "e4adfeba",
   "metadata": {
    "id": "e4adfeba",
    "outputId": "7c82360d-4c90-4cd1-9db4-7ba815277bbc",
    "ExecuteTime": {
     "end_time": "2025-03-09T09:22:25.264860Z",
     "start_time": "2025-03-09T09:22:20.951416Z"
    }
   },
   "source": [
    "response = chain_with_sources.invoke(\n",
    "    \"What is multihead?\"\n",
    ")\n",
    "\n",
    "print(\"Response:\", response['response'])\n",
    "\n",
    "print(\"\\n\\nContext:\")\n",
    "for text in response['context']['texts']:\n",
    "    print(text.text)\n",
    "    print(\"Page number: \", text.metadata.page_number)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "for image in response['context']['images']:\n",
    "    display_base64_image(image)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Multi-head attention is a mechanism in the Transformer model that allows the model to jointly attend to information from different representation subspaces at various positions. Instead of performing a single attention function with dmodel-dimensional keys, values, and queries, the model projects the queries, keys, and values multiple times (h times) using different learned linear projections. Each set of projections results in lower-dimensional representations (dk for keys and queries, dv for values), and the attention function is performed in parallel on these representations. The results are then concatenated and projected again to produce the final output.\n",
      "\n",
      "In the context of the Transformer model, multi-head attention enables the model to capture different types of relationships and interactions within the data, enhancing its ability to process sequences and improve performance on tasks such as translation and language modeling.\n",
      "\n",
      "\n",
      "Context:\n",
      "3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "Page number:  4\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "Page number:  4\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "7 Conclusion\n",
      "\n",
      "In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\n",
      "\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\n",
      "\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "\n",
      "The code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\n",
      "\n",
      "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
      "\n",
      "References\n",
      "\n",
      "[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.\n",
      "\n",
      "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.\n",
      "\n",
      "[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
      "\n",
      "[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint arXiv:1601.06733, 2016.\n",
      "\n",
      "10\n",
      "\n",
      "[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n",
      "\n",
      "[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357, 2016.\n",
      "\n",
      "[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n",
      "\n",
      "[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In Proc. of NAACL, 2016.\n",
      "\n",
      "[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu- tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n",
      "\n",
      "[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.\n",
      "\n",
      "[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- age recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016.\n",
      "\n",
      "[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001.\n",
      "\n",
      "[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.\n",
      "\n",
      "[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 832–841. ACL, August 2009.\n",
      "\n",
      "[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n",
      "\n",
      "[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016.\n",
      "\n",
      "[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on Learning Representations (ICLR), 2016.\n",
      "\n",
      "[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko- ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2, 2017.\n",
      "\n",
      "[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In International Conference on Learning Representations, 2017.\n",
      "\n",
      "[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n",
      "\n",
      "[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint arXiv:1703.10722, 2017.\n",
      "\n",
      "[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130, 2017.\n",
      "\n",
      "[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n",
      "\n",
      "[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention- based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n",
      "\n",
      "11\n",
      "\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n",
      "\n",
      "[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152–159. ACL, June 2006.\n",
      "\n",
      "[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\n",
      "\n",
      "[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.\n",
      "\n",
      "[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July 2006.\n",
      "\n",
      "[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv preprint arXiv:1608.05859, 2016.\n",
      "\n",
      "[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015.\n",
      "\n",
      "[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538, 2017.\n",
      "\n",
      "[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929–1958, 2014.\n",
      "\n",
      "[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015.\n",
      "\n",
      "[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n",
      "Page number:  10\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "7 Conclusion\n",
      "\n",
      "In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\n",
      "\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\n",
      "\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "\n",
      "The code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\n",
      "\n",
      "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
      "\n",
      "References\n",
      "\n",
      "[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.\n",
      "\n",
      "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.\n",
      "\n",
      "[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
      "\n",
      "[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint arXiv:1601.06733, 2016.\n",
      "\n",
      "10\n",
      "\n",
      "[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n",
      "\n",
      "[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357, 2016.\n",
      "\n",
      "[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n",
      "\n",
      "[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In Proc. of NAACL, 2016.\n",
      "\n",
      "[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu- tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n",
      "\n",
      "[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.\n",
      "\n",
      "[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- age recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016.\n",
      "\n",
      "[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001.\n",
      "\n",
      "[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.\n",
      "\n",
      "[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 832–841. ACL, August 2009.\n",
      "\n",
      "[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n",
      "\n",
      "[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016.\n",
      "\n",
      "[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on Learning Representations (ICLR), 2016.\n",
      "\n",
      "[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko- ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2, 2017.\n",
      "\n",
      "[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In International Conference on Learning Representations, 2017.\n",
      "\n",
      "[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n",
      "\n",
      "[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint arXiv:1703.10722, 2017.\n",
      "\n",
      "[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130, 2017.\n",
      "\n",
      "[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n",
      "\n",
      "[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention- based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n",
      "\n",
      "11\n",
      "\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n",
      "\n",
      "[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152–159. ACL, June 2006.\n",
      "\n",
      "[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\n",
      "\n",
      "[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.\n",
      "\n",
      "[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July 2006.\n",
      "\n",
      "[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv preprint arXiv:1608.05859, 2016.\n",
      "\n",
      "[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015.\n",
      "\n",
      "[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538, 2017.\n",
      "\n",
      "[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929–1958, 2014.\n",
      "\n",
      "[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015.\n",
      "\n",
      "[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n",
      "Page number:  10\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "id": "90cd3714",
   "metadata": {
    "id": "90cd3714"
   },
   "source": [
    "## References\n",
    "\n",
    "- [LangChain Inspiration](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb?ref=blog.langchain.dev)\n",
    "- [Multivector Storage](https://python.langchain.com/docs/how_to/multi_vector/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "74b56bde-1ba0-4525-a11d-cab02c5659e4",
    "8b55862c",
    "b1feadda-8171-4aed-9a60-320a88dc9ee1",
    "bb4d2379",
    "2bf26669",
    "4b45fb81-46b1-426e-aa2c-01aed4eac700",
    "69060724-e390-4dda-8250-5f86025c874a"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00b164fb36864e53a8a73710d7d855cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01ef4b60c3144e17afffb86281466bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "052ec73371404595b7dec973dda308d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e7ed203dde24ec9a8d0f9c95a8877fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15b9261bb07f4bbb95d276b92feabade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e7ed203dde24ec9a8d0f9c95a8877fd",
      "placeholder": "​",
      "style": "IPY_MODEL_e64cfd87330d4b238596da66db63d984",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "2045ffddb5c4407f9235d1bf472e9ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eab400a02dc46269e2537db44a78625",
      "placeholder": "​",
      "style": "IPY_MODEL_415ddcb74bc2467fa9399039b7d0cafb",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "21318da3ae0644c28ec63983a34bd2ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ad056a7d71847d498f270ecac5cbf62",
      "placeholder": "​",
      "style": "IPY_MODEL_309bad22d08c47af8d51942da599328e",
      "value": " 46.8M/46.8M [00:00&lt;00:00, 103MB/s]"
     }
    },
    "27e36e7f92d7417bb221fa95406cfb2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7185b40a7fa74088ad7ff6efb524e6b5",
      "max": 46807446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc6672c78dac468d9264efd90902c87d",
      "value": 46807446
     }
    },
    "2bcca7acc6f047d6ad4efbf1e5333c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2df0c4cc59044ec8a59aadf2d5d2a9c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2fc825e7e6949e0a18f491ff261ac2b",
      "max": 115434268,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df6e6c84cc1c4c7b8cf5f8555eb42166",
      "value": 115434268
     }
    },
    "2ee43f14fa654a66ad0cfb559826f266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00b164fb36864e53a8a73710d7d855cc",
      "max": 216625723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64a0c4aa0bba4b6f8e8f5775a4341147",
      "value": 216625723
     }
    },
    "3095817ccc8f4ec6bae9b0c201d8e40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_547eb1582628438c9f0ef01554dfcdb4",
      "placeholder": "​",
      "style": "IPY_MODEL_40b532d4d85740a2a16251bb321f489a",
      "value": " 115M/115M [00:02&lt;00:00, 36.9MB/s]"
     }
    },
    "309bad22d08c47af8d51942da599328e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3494ef9884224fa9a0a65999d7fc2945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bd05fe4e6bd4ea2b7bfcfba705369c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01ef4b60c3144e17afffb86281466bab",
      "placeholder": "​",
      "style": "IPY_MODEL_3494ef9884224fa9a0a65999d7fc2945",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "40b532d4d85740a2a16251bb321f489a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "415ddcb74bc2467fa9399039b7d0cafb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5246faf4e8194647a4b41d9de5a168f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8f31460d7d5420db2c7840e287fac5b",
       "IPY_MODEL_2ee43f14fa654a66ad0cfb559826f266",
       "IPY_MODEL_e7e6388db19d47ceb06afc75fbb8486c"
      ],
      "layout": "IPY_MODEL_922be25533bd448e9ce92614f7bd2677"
     }
    },
    "547eb1582628438c9f0ef01554dfcdb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ffb0b594f51466284af380fd4d47b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c13aff2b064743be941b4672550e56c9",
      "max": 1469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef5fba5f330748faa9bd583d637087a6",
      "value": 1469
     }
    },
    "64a0c4aa0bba4b6f8e8f5775a4341147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7185b40a7fa74088ad7ff6efb524e6b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ad056a7d71847d498f270ecac5cbf62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d37b6f0ba8b4c5eb875635b98778d26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "922be25533bd448e9ce92614f7bd2677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93205e664daa4921959605eb99dfa9cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eab400a02dc46269e2537db44a78625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9a67e81e91e46e19b23f58dea634525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2045ffddb5c4407f9235d1bf472e9ba5",
       "IPY_MODEL_2df0c4cc59044ec8a59aadf2d5d2a9c9",
       "IPY_MODEL_3095817ccc8f4ec6bae9b0c201d8e40a"
      ],
      "layout": "IPY_MODEL_93205e664daa4921959605eb99dfa9cc"
     }
    },
    "b12ba9f2111c44eeb5ae65820cc7d5d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15b9261bb07f4bbb95d276b92feabade",
       "IPY_MODEL_5ffb0b594f51466284af380fd4d47b40",
       "IPY_MODEL_fc994e0c5ced45c78c0b9bb6f19c073f"
      ],
      "layout": "IPY_MODEL_c58471c60519419e9cdb3c7ff174d702"
     }
    },
    "b2fc825e7e6949e0a18f491ff261ac2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c13aff2b064743be941b4672550e56c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c428c0bd915d455986b3193e9636ea80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c58471c60519419e9cdb3c7ff174d702": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8f31460d7d5420db2c7840e287fac5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f63ee7f4234c45d48829e011f24eafde",
      "placeholder": "​",
      "style": "IPY_MODEL_f8bcfb1381aa46d89034ea50e30b43cf",
      "value": "Downloading yolox_l0.05.onnx: 100%"
     }
    },
    "cc6672c78dac468d9264efd90902c87d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "daabde9b4b764797af6b96370e40c1d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6e6c84cc1c4c7b8cf5f8555eb42166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e64cfd87330d4b238596da66db63d984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7e6388db19d47ceb06afc75fbb8486c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bcca7acc6f047d6ad4efbf1e5333c58",
      "placeholder": "​",
      "style": "IPY_MODEL_052ec73371404595b7dec973dda308d4",
      "value": " 217M/217M [00:07&lt;00:00, 37.2MB/s]"
     }
    },
    "ef5fba5f330748faa9bd583d637087a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef897646c62444929b91935d3917b14d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bd05fe4e6bd4ea2b7bfcfba705369c5",
       "IPY_MODEL_27e36e7f92d7417bb221fa95406cfb2f",
       "IPY_MODEL_21318da3ae0644c28ec63983a34bd2ee"
      ],
      "layout": "IPY_MODEL_c428c0bd915d455986b3193e9636ea80"
     }
    },
    "f63ee7f4234c45d48829e011f24eafde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8bcfb1381aa46d89034ea50e30b43cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc994e0c5ced45c78c0b9bb6f19c073f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daabde9b4b764797af6b96370e40c1d2",
      "placeholder": "​",
      "style": "IPY_MODEL_7d37b6f0ba8b4c5eb875635b98778d26",
      "value": " 1.47k/1.47k [00:00&lt;00:00, 66.9kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
